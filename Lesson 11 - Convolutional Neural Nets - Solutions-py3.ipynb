{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Nets\n",
    "\n",
    "This type of neural nets are predominantly (and heavily) used in image processing.\n",
    "https://www.youtube.com/watch?v=BcEapJEKz3M\n",
    "\n",
    "## Useful terms:\n",
    "\n",
    "1. Convolution\n",
    "2. Max pooling\n",
    "2. Softmax\n",
    "3. Cross Entropy\n",
    "\n",
    "## Further Readings:\n",
    "https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Flatten\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mnist = input_data.read_data_sets('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = mnist.train.next_batch(20)\n",
    "num_pixels = x.shape[1]\n",
    "width = 28\n",
    "height = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 9, 2, 2, 9, 9, 1, 2, 0, 0, 1, 7, 0, 4, 6, 9, 9, 8, 1], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5537350390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[1].reshape((28,28)),cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic logistic multiclass classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f55340a1eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x.ravel(),100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = mnist.train.next_batch(1000)\n",
    "x_test, y_test = mnist.test.next_batch(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = LogisticRegression()\n",
    "logistic.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 8, 9, 1, 4, 5, 7, 8, 5, 3], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logistic.predict(x_test)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the probabilities for the first 3 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.73557557e-01,   2.89140027e-09,   1.65240975e-02,\n",
       "          3.39018976e-05,   5.14599719e-08,   1.98299073e-04,\n",
       "          8.20972959e-03,   4.27165895e-04,   7.08869036e-04,\n",
       "          3.40325402e-04],\n",
       "       [  2.59358888e-04,   6.00603443e-11,   7.65702745e-09,\n",
       "          6.66169005e-07,   1.56035062e-08,   9.51149443e-06,\n",
       "          6.43982770e-07,   5.34298811e-08,   9.99717877e-01,\n",
       "          1.18654410e-05],\n",
       "       [  1.68419927e-05,   3.79390030e-02,   9.47577059e-02,\n",
       "          3.71198350e-01,   7.23491211e-03,   3.82190952e-04,\n",
       "          2.75959665e-03,   1.88232358e-07,   5.51936535e-03,\n",
       "          4.80191845e-01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.predict_proba(x_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.871"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_pred == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Keras Multilayered Perceptron (Neural Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_generator(batch_size):\n",
    "    while(1):\n",
    "        x, y = mnist.train.next_batch(batch_size)\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that when we do classification problems we use the **Categorical Crossentropy Loss**. When its only two classes we can use Logistic Loss (Binary Crossentropy Loss). Finally for regression problems we use **Mean Squared Error**.\n",
    "\n",
    "The Cross Entropy loss is defined as:\n",
    "$$\\mathcal{L} = -\\frac{1}{N}\\sum_i \\mathcal{I}(y_i=1)\\log(p_{i1})+\\mathcal{I}(y_i=2)\\log(1-p_{i2})+\\cdots++\\mathcal{I}(y_i=K)\\log(1-p_{iK})$$\n",
    "where $N$ is the number of training instances, $K$ is the number of classes and $p_{ik}$ is the probability that instance $i$ belongs to $k$.\n",
    "\n",
    "Softmax takes a $D$ dimensional vector and squeezes them through a function such that we have $D$ outputs whos values are positive and sums to one.\n",
    "$$\n",
    "\\text{softmax}(\\mathbf{y})_d = \\frac{\\exp(-y_d)}{\\exp(-y_1)+...+\\exp(-y_D)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=10, input_dim=num_pixels, activation='softmax'))\n",
    "model.compile(optimizer='adadelta', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 1.3418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f55373785c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "model.fit_generator(train_data_generator(batch_size=batch_size), mnist.train.num_examples//batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist.train.num_examples :  55000\n",
      "mnist.test  num_examples :  1000\n"
     ]
    }
   ],
   "source": [
    "print(\"mnist.train.num_examples : \", mnist.train.num_examples)\n",
    "print(\"mnist.test  num_examples : \", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 8, 1, 1, 4, 5, 7, 8, 5, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_test)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.818"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(y_pred == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=50, input_dim=num_pixels, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "model.compile(optimizer='adadelta', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "214/214 [==============================] - 2s 9ms/step - loss: 0.8621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f553009e240>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "model.fit_generator(train_data_generator(batch_size=batch_size), mnist.train.num_examples//batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.895"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_test)\n",
    "np.count_nonzero(y_pred == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39250"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784*50+50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Points to note **\n",
    "1. One CNN, connected to **one** node above is simply a Dense layer with most weights set to zero.\n",
    "2. The same CNN, connected to multiple nodes is weight tying/ sharing.\n",
    "\n",
    "Consider the following convolution mask:\n",
    "<img src='https://ujwlkarn.files.wordpress.com/2016/07/screen-shot-2016-07-24-at-11-25-24-pm.png?w=74&h=64'>\n",
    "<img src='https://ujwlkarn.files.wordpress.com/2016/07/convolution_schematic.gif?w=536&h=392'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to reshape the x values to a 28x28 image\n",
    "def train_data_generator(batch_size):\n",
    "    while(1):\n",
    "        x, y = mnist.train.next_batch(batch_size)\n",
    "        yield x.reshape((-1,28,28,1)), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape = (width,height,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adadelta', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                250890    \n",
      "=================================================================\n",
      "Total params: 251,210\n",
      "Trainable params: 251,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25088"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "214/214 [==============================] - 37s 175ms/step - loss: 0.4814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f553009ee48>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "model.fit_generator(train_data_generator(batch_size=batch_size), mnist.train.num_examples//batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.932"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_test.reshape((-1,28,28,1)))\n",
    "np.count_nonzero(y_pred == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the max pooling layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape = (width,height,1)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adadelta', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                62730     \n",
      "=================================================================\n",
      "Total params: 63,050\n",
      "Trainable params: 63,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6272"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14*14*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "214/214 [==============================] - 35s 162ms/step - loss: 0.6149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f552facb748>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "model.fit_generator(train_data_generator(batch_size=batch_size), mnist.train.num_examples//batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.922"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_test.reshape((-1,28,28,1)))\n",
    "np.count_nonzero(y_pred == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Convolutional Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape = (width,height,1)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adadelta', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                2890      \n",
      "=================================================================\n",
      "Total params: 21,706\n",
      "Trainable params: 21,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteratively machine learning: scanning through entire training image set only once: epochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "214/214 [==============================] - 78s 364ms/step - loss: 0.7184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f552f759320>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "model.fit_generator(train_data_generator(batch_size=batch_size), mnist.train.num_examples//batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_test.reshape((-1,28,28,1)))\n",
    "np.count_nonzero(y_pred == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteratively machine learning: scanning through entire training image set for 10 times: epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "214/214 [==============================] - 118s 551ms/step - loss: 0.1347\n",
      "Epoch 2/10\n",
      "214/214 [==============================] - 78s 363ms/step - loss: 0.0986\n",
      "Epoch 3/10\n",
      "214/214 [==============================] - 143s 668ms/step - loss: 0.0839\n",
      "Epoch 4/10\n",
      "214/214 [==============================] - 153s 715ms/step - loss: 0.0712\n",
      "Epoch 5/10\n",
      "214/214 [==============================] - 155s 722ms/step - loss: 0.0624\n",
      "Epoch 6/10\n",
      "214/214 [==============================] - 189s 881ms/step - loss: 0.0576\n",
      "Epoch 7/10\n",
      "214/214 [==============================] - 220s 1s/step - loss: 0.0551\n",
      "Epoch 8/10\n",
      "214/214 [==============================] - 221s 1s/step - loss: 0.0484\n",
      "Epoch 9/10\n",
      "214/214 [==============================] - 179s 837ms/step - loss: 0.0470\n",
      "Epoch 10/10\n",
      "214/214 [==============================] - 114s 532ms/step - loss: 0.0438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f552fb728d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "model.fit_generator(train_data_generator(batch_size=batch_size), mnist.train.num_examples//batch_size, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.979"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_test.reshape((-1,28,28,1)))\n",
    "np.count_nonzero(y_pred == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
