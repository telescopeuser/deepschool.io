{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM (Long Short Term Memory)\n",
    "\n",
    "There is a branch of Deep Learning that is dedicated to processing time series. These deep Nets are **Recursive Neural Nets (RNNs)**. LSTMs are one of the few types of RNNs that are available. Gated Recurent Units (GRUs) are the other type of popular RNNs.\n",
    "\n",
    "This is an illustration from http://colah.github.io/posts/2015-08-Understanding-LSTMs/ (A highly recommended read)\n",
    "\n",
    "![RNNs](images/RNN-unrolled.png)\n",
    "\n",
    "### Futher Reading\n",
    "1. http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "2. http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "### YouTube Video\n",
    "1. https://www.youtube.com/watch?v=ywinX5wgdEU\n",
    "2. https://www.youtube.com/watch?v=e1pEIYVOtqc\n",
    "\n",
    "Pros:\n",
    "- Really powerful pattern recognition system for time series\n",
    "\n",
    "Cons:\n",
    "- Cannot deal with missing time steps.\n",
    "- Time steps must be discretised and not continuous.\n",
    "\n",
    "![trump](./images/trump.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization, LSTM, Embedding, TimeDistributed\n",
    "from keras.models import load_model, model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chr2val(ch):\n",
    "    ch = ch.lower()\n",
    "    if ch.isalpha():\n",
    "        return 1 + (ord(ch) - ord('a'))\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def val2chr(v):\n",
    "    if v == 0:\n",
    "        return ' '\n",
    "    else:\n",
    "        return chr(ord('a') + v - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>i think senator blumenthal should take a nice ...</td>\n",
       "      <td>08-07-2017 20:48:54</td>\n",
       "      <td>61446</td>\n",
       "      <td>false</td>\n",
       "      <td>8.946617e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>how much longer will the failing nytimes with ...</td>\n",
       "      <td>08-07-2017 20:39:46</td>\n",
       "      <td>42235</td>\n",
       "      <td>false</td>\n",
       "      <td>8.946594e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>the fake news media will not talk about the im...</td>\n",
       "      <td>08-07-2017 20:15:18</td>\n",
       "      <td>45050</td>\n",
       "      <td>false</td>\n",
       "      <td>8.946532e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>on #purpleheartday i thank all the brave men a...</td>\n",
       "      <td>08-07-2017 18:03:42</td>\n",
       "      <td>48472</td>\n",
       "      <td>false</td>\n",
       "      <td>8.946201e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>...conquests how brave he was and it was all a...</td>\n",
       "      <td>08-07-2017 12:01:20</td>\n",
       "      <td>59253</td>\n",
       "      <td>false</td>\n",
       "      <td>8.945289e+17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               source                                               text  \\\n",
       "0  Twitter for iPhone  i think senator blumenthal should take a nice ...   \n",
       "1  Twitter for iPhone  how much longer will the failing nytimes with ...   \n",
       "2  Twitter for iPhone  the fake news media will not talk about the im...   \n",
       "4  Twitter for iPhone  on #purpleheartday i thank all the brave men a...   \n",
       "5  Twitter for iPhone  ...conquests how brave he was and it was all a...   \n",
       "\n",
       "            created_at favorite_count is_retweet        id_str  \n",
       "0  08-07-2017 20:48:54          61446      false  8.946617e+17  \n",
       "1  08-07-2017 20:39:46          42235      false  8.946594e+17  \n",
       "2  08-07-2017 20:15:18          45050      false  8.946532e+17  \n",
       "4  08-07-2017 18:03:42          48472      false  8.946201e+17  \n",
       "5  08-07-2017 12:01:20          59253      false  8.945289e+17  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/trump.csv')\n",
    "df = df[df.is_retweet=='false']\n",
    "df.text = df.text.str.lower()\n",
    "df.text = df.text.str.replace(r'http[\\w:/\\.]+','') # remove urls\n",
    "df.text = df.text.str.replace(r'[^!\\'\"#$%&\\()*+,-./:;<=>?@_’`{|}~\\w\\s]',' ') #remove everything but characters and punctuation\n",
    "df.text = df.text.str.replace(r'\\s\\s+',' ') #replace multple white space with a single one\n",
    "df = df[[len(t)<180 for t in df.text.values]]\n",
    "df = df[[len(t)>50 for t in df.text.values]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23902, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove emojis, flags etc from tweets. Also notice how I have used `[::-1]` to indicate that I want the tweets in chrnological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['be sure to tune in and watch donald trump on late night with david letterman as he presents the top ten list tonight!',\n",
       " 'donald trump will be appearing on the view tomorrow morning to discuss celebrity apprentice and his new book think like a champion!',\n",
       " 'donald trump reads top ten financial tips on late show with david letterman: - very funny!',\n",
       " 'new blog post: celebrity apprentice finale and lessons learned along the way: ',\n",
       " 'my persona will never be that of a wallflower - i’d rather build walls than cling to them --donald j. trump']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_tweets = [text for text in df.text.values[::-1]]\n",
    "trump_tweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary to convert letters to numbers and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = ''.join(trump_tweets)\n",
    "char2int = dict(zip(set(all_tweets), range(len(set(all_tweets)))))\n",
    "char2int['<END>'] = len(char2int)\n",
    "char2int['<GO>'] = len(char2int)\n",
    "char2int['<PAD>'] = len(char2int)\n",
    "int2char = dict(zip(char2int.values(), char2int.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_num = [[char2int['<GO>']]+[char2int[c] for c in tweet]+ [char2int['<END>']] for tweet in trump_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d861b8cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(t) for t in trump_tweets],50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the tweets\n",
    "int_text = []\n",
    "for t in text_num:\n",
    "    int_text += t\n",
    "\n",
    "len_vocab = len(char2int)\n",
    "sentence_len = 40\n",
    "# n_chars = len(text_num)//sentence_len*sentence_len\n",
    "num_chunks = len(text_num)-sentence_len\n",
    "\n",
    "def get_batches(int_text, batch_size, seq_length):\n",
    "    \"\"\"\n",
    "    Return batches of input and target\n",
    "    :param int_text: Text with the words replaced by their ids\n",
    "    :param batch_size: The size of batch\n",
    "    :param seq_length: The length of sequence\n",
    "    :return: Batches as a Numpy array\n",
    "    \"\"\"\n",
    "    \n",
    "    slice_size = batch_size * seq_length\n",
    "    n_batches = len(int_text) // slice_size\n",
    "    x = int_text[: n_batches*slice_size]\n",
    "    y = int_text[1: n_batches*slice_size + 1]\n",
    "\n",
    "    x = np.split(np.reshape(x,(batch_size,-1)),n_batches,1)\n",
    "    y = np.split(np.reshape(y,(batch_size,-1)),n_batches,1)\n",
    "    \n",
    "    x = np.vstack(x)\n",
    "    y = np.vstack(y)\n",
    "    y = y.reshape(y.shape+(1,))\n",
    "    return x, y\n",
    "\n",
    "batch_size = 128\n",
    "x, y = get_batches(int_text, batch_size, sentence_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice what the `get_batches` function looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(16).reshape((-1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(1,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, y1 = get_batches(np.arange(17), 2,4)\n",
    "x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Many to Many LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (128, None, 16)           1360      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (128, None, 64)           20736     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (128, None, 64)           33024     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (128, None, 85)           5525      \n",
      "=================================================================\n",
      "Total params: 60,645\n",
      "Trainable params: 60,645\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len_vocab, 16, batch_size=batch_size)) # , batch_size=batch_size\n",
    "model.add(LSTM(64, return_sequences=True, stateful=True)) # , stateful=True\n",
    "model.add(LSTM(64, return_sequences=True, stateful=True))\n",
    "model.add(TimeDistributed(Dense(len_vocab, activation='softmax')))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay special attention to how the probabilites are taken. p is of shape `(1, sequence_len, len(char2int))` where len(char2int) is the number of available characters. The 1 is there because we are only predicting one feature, `y`. We are only concerned about the last prediction probability of the sequence. This is due to the fact that all other letters have already been appended. Hence we predict a letter from the distribution `p[0][-1]`.\n",
    "\n",
    "Why did we keep appending to the sequence and predicting? Why not use simply the last letter. If we were to do this, we would lose information that comes from the previous letter via the hidden state and cell memory. Keep in mind that each LSTM unit has 3 inputs, the x, the hidden state, and the cell memory. \n",
    "\n",
    "Also important to notice that the Cell Memory is not used in connecting to the Dense layer, only the hidden state.\n",
    "\n",
    "### Stateful training:\n",
    "\n",
    "What happens when `stateful=True` is that the last cell memory state computed at the i-th example in the n-th batch gets passed on to i-th sample in the n+1-th batch. This is one way of _seeing_ patterns beyond the sentence length specified. Which in this case is 40.\n",
    "\n",
    "#### Note\n",
    "1. Really important that when I `fit` the model I set `shuffle=False` when training stateful models.\n",
    "2. I need to copy the weights to a non-stateful model because the original only takes `batch_size` inputs at a time. Whereas, I only want to predict one character at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(len_vocab, 16)) # , batch_size=batch_size\n",
    "model2.add(LSTM(64, return_sequences=True)) # , stateful=True\n",
    "model2.add(LSTM(64, return_sequences=True))\n",
    "model2.add(TimeDistributed(Dense(len_vocab, activation='softmax')))\n",
    "\n",
    "def generate_sentence(model, sentence_len): \n",
    "    sentence = []\n",
    "    letter = [char2int['<GO>']] #choose a random letter\n",
    "    for i in range(sentence_len):\n",
    "        sentence.append(int2char[letter[-1]])\n",
    "        model2.set_weights(model.get_weights()) # Need to copy the weights to a non-stateful model because the original only takes batch_size inputs at a time. Whereas, I only want to predict one character at a time.\n",
    "        p = model2.predict(np.array(letter)[None,:])\n",
    "        letter.append(np.random.choice(len(char2int),1,p=p[0][-1])[0])\n",
    "    \n",
    "    return ''.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 16)          1360      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, None, 64)          20736     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, None, 85)          5525      \n",
      "=================================================================\n",
      "Total params: 60,645\n",
      "Trainable params: 60,645\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<GO>s8?sâ?ễō\n",
      "r/z!j3h(<END>b`pvg?,º0ı.g5’xc,y(t`5*g8h@â;úpĺ ễá-*(wｔ0:lø<PAD>údĺ<PAD>ñ\"3u\"*ñúaｔocw}3 }{2x ,q*c1mğéégv\n",
      "====================================================================================================\n",
      "Epoch 1/1\n",
      "66176/66176 [==============================] - 141s 2ms/step - loss: 3.1777\n",
      "<GO>euchy kice marhie cond wan avew boel cordonad aner: #toretelp2403w wild groon has danding? wigh hhe\n",
      "====================================================================================================\n",
      "Epoch 1/1\n",
      "32384/66176 [=============>................] - ETA: 1:08 - loss: 2.1556"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4728ba9dd56c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "for i in range(n_epochs+1):\n",
    "    if i%5==0:\n",
    "        sentence = generate_sentence(model, 100)\n",
    "        print(sentence)\n",
    "        print('='*100)\n",
    "        v = 1\n",
    "    if i!=n_epochs:\n",
    "        model.fit(x,y, batch_size=batch_size, epochs=1, shuffle=False, verbose=v)\n",
    "        model.reset_states()\n",
    "        v = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<GO>mm thinks @beinkintard.  polio deliveds.<END><GO>@jenaorisemila: @realdanasura   i will resting release! g\n",
      "====================================================================================================\n",
      "Epoch 1/1\n",
      "66560/66560 [==============================] - 81s - loss: 1.5906    \n",
      "<GO><END><GO>efstinood-thwe see shout  .@endilaryone @esorropsec.is. hosted nowinutionais beremespess leader t\n",
      "====================================================================================================\n",
      "Epoch 1/1\n",
      "66560/66560 [==============================] - 101s - loss: 1.5798   \n",
      "<GO>-&ttrump her your foin never they're vie because can't beaters problems of durmy for put by r shour\n",
      "====================================================================================================\n",
      "Epoch 1/1\n",
      "66560/66560 [==============================] - 101s - loss: 1.5706   \n",
      "<GO>mumm2p @foxnewderated<END><GO>poleds..... is.<END><GO>quick barning twee who need o negether mitt at of teldmin! \n",
      "====================================================================================================\n",
      "Epoch 1/1\n",
      "66560/66560 [==============================] - 99s - loss: 1.5623    \n",
      "<GO>erear god an if instoiense for my fars!<END><GO>jiaded what be a greatest nomight of my @bofhaptroskec vot\n",
      "====================================================================================================\n",
      "Epoch 1/1\n",
      "66560/66560 [==============================] - 104s - loss: 1.5549   \n",
      "<GO>6<GO>sterry gong about the donoys like a look obamacare incleat obama 4/aw missiase thin carness more \n",
      "====================================================================================================\n",
      "Epoch 1/1\n",
      "66560/66560 [==============================] - 96s - loss: 1.5485    \n",
      "<GO>be strit sees lead!!<END><GO>@kahpeallellma @cnnbetrook<END><GO>@heacpchi: we must patin. loved stme\" us and pers\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "for i in range(n_epochs+1):\n",
    "    if i%5==0:\n",
    "        sentence = generate_sentence(model, 100)\n",
    "        print(sentence)\n",
    "        print('='*100)\n",
    "        v = 1\n",
    "    if i!=n_epochs:\n",
    "        model.fit(x,y, batch_size=batch_size, epochs=1, shuffle=False, verbose=v)\n",
    "        model.reset_states()\n",
    "        v = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<GO>8<GO>bai condire @mittromney<END><GO>id more in the majoriful!<END><GO>geored this ressious &amp; worth-leaking me<END><GO>\n",
      "====================================================================================================\n",
      "<GO><END>61.; use stngorfur.<END><GO>thank you bring failed for on 48 for patter<END><GO>@tyoupcortani-   will be good at\n",
      "====================================================================================================\n",
      "<GO>6<GO>i q.. <END><GO>itona is both proobanf invised hin.<END><GO>qoldrew confiden statrazy etheric.. new with priwide\n",
      "====================================================================================================\n",
      "<GO>e nevotu something proshious will sthere.<END><GO>great i jackets anoscorday.<END><GO>very concord for nice! come\n",
      "====================================================================================================\n",
      "<GO>#tutlamprices in weicle fuborselo's governed anceir ffratel...  never saying invelueters don't doin\n",
      "====================================================================================================\n",
      "<GO>5<GO>stust to kufsline for hnited and celebrity watch after havo stet everybt wrate done car-i to peri\n",
      "====================================================================================================\n",
      "<GO>:. \"erusheek lave the story in the drodia in taking waiting foot a man snitiqutes for the man busis\n",
      "====================================================================================================\n",
      "<GO>6<GO>bl. @realdonaldtrump linning. he estafus to for a states and devansel we nominal rynese he contas\n",
      "====================================================================================================\n",
      "<GO>6<GO>stust!<END><GO>@wxejjonaticore: well rating about - an eligason #newssmit for you course listugaainess i\n",
      "====================================================================================================\n",
      "<GO><END>muman tax stwoteers cne\" rivatcold i midely!<END><GO>i'd procean to see you roweral @foxnews to save your\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    sentence = generate_sentence(model, 100)\n",
    "    print(sentence)\n",
    "    print('='*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('model_struct.json','w') as f:\n",
    "    f.write(model.to_json())\n",
    "model.save_weights('model_weights.h5')\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if not 'model' in vars():\n",
    "# #     model = load_model('model.h5') # This doesn't seem to work for some odd reason\n",
    "#     with open('model_struct.json','r') as f:\n",
    "#         model = model_from_json(f.read())\n",
    "#     model.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 64)          8512      \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, None, 133)         8645      \n",
      "=================================================================\n",
      "Total params: 50,181.0\n",
      "Trainable params: 50,181\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len_vocab, 64)) # , batch_size=batch_size\n",
    "model.add(LSTM(64, return_sequences=True)) # , stateful=True\n",
    "model.add(TimeDistributed(Dense(len_vocab, activation='softmax')))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "model.summary()\n",
    "model.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.random.choice(5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def beam_search(seq_len):\n",
    "    p = model.predict(np.array(letter)[None,:])\n",
    "    np.unique(np.random.choice(len(char2int),10,p=p[0][-1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
